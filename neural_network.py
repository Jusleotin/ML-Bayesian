# -*- coding: utf-8 -*-
"""Neural Network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CQTLfK_zVg8kEeSkrOSoDhgZvf_nmGs_
"""

# Commented out IPython magic to ensure Python compatibility.
# Imported Libraries

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA, TruncatedSVD
import matplotlib.patches as mpatches
import time

# Classifier Libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import collections

# Other Libraries
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.pipeline import make_pipeline
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from sklearn.model_selection import cross_val_score
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, mean_squared_error
from collections import Counter
from sklearn.model_selection import KFold, StratifiedKFold
import warnings
warnings.filterwarnings("ignore")

# %matplotlib inline

"""**Section 1** \\
**Data Pre-processing**
"""

from google.colab import drive
drive.mount('/content/drive')
file_path = '/content/drive/My Drive/MLB_Project/creditcard.csv'  #sometimes the path of file may change
# https://drive.google.com/file/d/1tU0rBm7iWynzoaBX6zzCWuEzT3kl9Vr7/view?usp=drive_link
data = pd.read_csv(file_path) # Reading the file .csv
df = pd.DataFrame(data) # Converting data to Panda DataFrame

# df.shape
df.describe()

target = df['Class'].value_counts()
num_legit = target[0]
num_fraud = target[1]
print(num_legit)
print(num_fraud)

fig, ax = plt.subplots(1, 2, figsize=(18,4))

amount_val = df['Amount'].values
time_val = df['Time'].values

sns.distplot(amount_val, ax=ax[0], color='r')
ax[0].set_title('Distribution of Transaction Amount', fontsize=14)
ax[0].set_xlim([min(amount_val), max(amount_val)])

sns.distplot(time_val, ax=ax[1], color='b')
ax[1].set_title('Distribution of Transaction Time', fontsize=14)
ax[1].set_xlim([min(time_val), max(time_val)])



plt.show()

"""From the Histogram above we can conclude that the data set is unbalanced thus we need to re-select the data for training so we need to create a **sub-sample** set. Besides, all of the data have been scaled except **Time** and **Amount**, we gonna scale them."""

from sklearn.preprocessing import StandardScaler, RobustScaler

# RobustScaler is less prone to outliers.

std_scaler = StandardScaler()
rob_scaler = RobustScaler()

df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))
df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))

df.drop(['Time','Amount'], axis=1, inplace=True)

# After that, we split the data, and then undersampling

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit

print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')
print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')

X = df.drop('Class', axis=1)
y = df['Class']

sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)

for train_index, test_index in sss.split(X, y):
    print("Train:", train_index, "Test:", test_index)
    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]
    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]

# Turn into an array
original_Xtrain = original_Xtrain.values
original_Xtest = original_Xtest.values
original_ytrain = original_ytrain.values
original_ytest = original_ytest.values

# See if both the train and test label distribution are similarly distributed
train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)
test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)
print('-' * 100)

print('Label Distributions: \n')
print(train_counts_label/ len(original_ytrain))
print(test_counts_label/ len(original_ytest))

## Sub-sampling

df = df.sample(frac=1)

# amount of fraud classes 492 rows keep them consistent.
fraud_df = df.loc[df['Class'] == 1]
non_fraud_df = df.loc[df['Class'] == 0][:492]

normal_distributed_df = pd.concat([fraud_df, non_fraud_df])

# Shuffle dataframe rows
new_df = normal_distributed_df.sample(frac=1, random_state=42)

new_df.shape
print('Distribution of the Classes in the subsample dataset')
print(new_df['Class'].value_counts()/len(new_df))

## Split the balanced data into train and test
X = new_df.drop('Class', axis=1)
y = new_df['Class']

"""**Section 2**

**Undersampling and model selection**
"""

#### No NearMiss

from imblearn.under_sampling import NearMiss
from collections import Counter

nm = NearMiss()

# Undersample the majority class
X_resampled, y_resampled = nm.fit_resample(X, y)

print("Class distribution after Near-Miss undersampling:", Counter(y_resampled))


X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Turn the values into an array for feeding the classification algorithms.
X_train = X_train.values
X_test = X_test.values
y_train = y_train.values
y_test = y_test.values

!pip install scikeras
from scikeras.wrappers import KerasClassifier, KerasRegressor

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

model = Sequential()

model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(64, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True, verbose=1)

model.fit(X_train, y_train, epochs=50, batch_size=1024, validation_split=0.1, callbacks=[checkpoint], verbose=1)

best_model = tf.keras.models.load_model('best_model.h5')

# Grid Search

from sklearn.model_selection import GridSearchCV
# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier

# Define a function that creates your model

def create_model(activation='relu', optimizer='adam'):
    model = Sequential()
    model.add(Dense(512, input_dim=X_train.shape[1], activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(256, activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(128, activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(64, activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(32, activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(32, activation=activation))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Create a KerasClassifier based on your model
keras_model = KerasClassifier(build_fn=create_model, activation='relu')

# Define the grid search parameters including activation functions
param_grid = {
    'activation': ['relu', 'tanh', 'sigmoid'],
    'batch_size': [512, 1024],
    'epochs': [50, 100],
    'optimizer': ['adam', 'rmsprop']
}

# Create and run the grid search
grid = GridSearchCV(estimator=keras_model, param_grid=param_grid, cv=3)
grid_result = grid.fit(X_train, y_train)

# Print the best parameters found
print("Best parameters: ", grid_result.best_params_)

keras_model = KerasClassifier(build_fn=create_model, activation='relu', optimizer = 'adam')
print(keras_model)
keras_model.fit(X_train, y_train, validation_split=0.1, batch_size=512, epochs=100, shuffle=True, verbose=2)
y_pred = keras_model.predict(X_test)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)

# Precision
precision = precision_score(y_test, y_pred)

# Recall
recall = recall_score(y_test, y_pred)

# F1-score
f1 = f1_score(y_test, y_pred)

# Mean Squared Error (for regression problems, not classification)
mse = mean_squared_error(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("MSE:", mse)

undersample_predictions = keras_model.predict(original_Xtest, batch_size=1024, verbose=0)

# undersample_fraud_predictions = keras_model.predict_classes(original_Xtest, batch_size=1024, verbose=0)

import itertools
from sklearn.metrics import confusion_matrix

# Create a confusion matrix
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title, fontsize=14)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

undersample_cm = confusion_matrix(original_ytest, undersample_predictions)
actual_cm = confusion_matrix(original_ytest, original_ytest)
labels = ['No Fraud', 'Fraud']

fig = plt.figure(figsize=(16,8))

fig.add_subplot(221)
plot_confusion_matrix(undersample_cm, labels, title="Random UnderSample \n Confusion Matrix", cmap=plt.cm.Reds)

fig.add_subplot(222)
plot_confusion_matrix(actual_cm, labels, title="Confusion Matrix \n (with 100% accuracy)", cmap=plt.cm.Greens)

"""**Section 3**

**Oversampling -> SMOTE for neural network**
"""

# SMOTE Technique (OverSampling) After splitting and Cross Validating
sm = SMOTE(random_state=42)

# This will be the data were we are going to
X_train_S, y_train_S = sm.fit_resample(original_Xtrain, original_ytrain)

keras_model.fit(X_train_S, y_train_S, validation_split=0.2, batch_size=512, epochs=100, shuffle=True, verbose=2)

from sklearn.model_selection import cross_val_score

training_score = cross_val_score(keras_model, X_train_S, y_train_S, cv=5)

y_pred = keras_model.predict(original_Xtest)

# Accuracy
accuracy = accuracy_score(original_ytest, y_pred)

# Precision
precision = precision_score(original_ytest, y_pred)

# Recall
recall = recall_score(original_ytest, y_pred)

# F1-score
f1 = f1_score(original_ytest, y_pred)

# Mean Squared Error (for regression problems, not classification)
mse = mean_squared_error(original_ytest, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)
print("MSE:", mse)

oversample_predictions = keras_model.predict(original_Xtest, batch_size=1024, verbose=0)

oversample_smote = confusion_matrix(original_ytest, oversample_predictions)
actual_cm = confusion_matrix(original_ytest, original_ytest)
labels = ['No Fraud', 'Fraud']

fig = plt.figure(figsize=(16,8))

fig.add_subplot(221)
plot_confusion_matrix(oversample_smote, labels, title="OverSample (SMOTE) \n Confusion Matrix", cmap=plt.cm.Oranges)

fig.add_subplot(222)
plot_confusion_matrix(actual_cm, labels, title="Confusion Matrix \n (with 100% accuracy)", cmap=plt.cm.Greens)